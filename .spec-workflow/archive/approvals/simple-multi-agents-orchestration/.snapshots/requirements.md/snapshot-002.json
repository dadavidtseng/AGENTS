{
  "id": "snapshot_1764496851436_1uuwbzafh",
  "approvalId": "approval_1764494848260_rc43um6z3",
  "approvalTitle": "Requirements Document - Simple Multi-Agent Orchestration",
  "version": 2,
  "timestamp": "2025-11-30T10:00:51.436Z",
  "trigger": "revision_requested",
  "status": "pending",
  "content": "# Requirements: Simple Multi-Agent Orchestration\n\n**Spec Name:** `simple-multi-agents-orchestration`\n**Created:** 2025-11-30\n**Status:** Draft - Pending Approval\n\n---\n\n## 1. Overview\n\n### 1.1 Purpose\nEnable agent-producer to act as an intelligent orchestrator that receives user requests from multiple channels (Claude Desktop, Claude Code, Slack, Discord), breaks down work into structured tasks using the shrimp-AGENTS MCP server, distributes tasks to worker agents via KÄ€DI event-driven architecture, monitors execution, and coordinates verification and user feedback.\n\n### 1.2 Background\nCurrent multi-agent systems lack centralized orchestration. Each agent operates independently, requiring manual coordination for complex projects. This feature introduces a \"producer\" agent pattern that leverages:\n- **shrimp-AGENTS MCP server** for centralized task/spec management\n- **KÄ€DI broker** for event-driven agent communication\n- **Multi-channel support** for unified user experience across interfaces\n\n### 1.3 Goals\n- **G1:** Automate project decomposition from user requirements to executable tasks\n- **G2:** Enable hands-free task distribution to appropriate worker agents\n- **G3:** Provide real-time progress visibility across all channels\n- **G4:** Ensure quality through systematic verification before user review\n- **G5:** Handle failures gracefully with automatic reassignment\n\n---\n\n## 2. User Stories\n\n### Epic 1: Request Processing\n\n**US-1.1:** As a **user**, I want to **submit feature requests via Claude Desktop, Claude Code, Slack, or Discord**, so that **I can use my preferred interface**.\n\n- **EARS Criteria:**\n  - **WHEN** user sends message \"Can you create a design document to make a cube spinning randomly and changes color gradually?\" via any supported channel\n  - **THEN** agent-producer receives request with channel context (user ID, channel type, thread/conversation ID)\n  - **AND** acknowledges receipt within 2 seconds\n\n**US-1.2:** As a **user**, I want to **receive immediate acknowledgment of my request**, so that **I know the system is processing it**.\n\n- **EARS Criteria:**\n  - **WHEN** agent-producer receives user request\n  - **THEN** responds with acknowledgment message in same channel\n  - **AND** includes estimated planning time\n  - **Example:** \"Got it! Planning your spinning color cube project. This should take about 1-2 minutes...\"\n\n---\n\n### Epic 2: Task Planning & Breakdown\n\n**US-2.1:** As a **agent-producer**, I want to **call shrimp-AGENTS MCP server to create project specifications**, so that **requirements are structured and traceable**.\n\n- **EARS Criteria:**\n  - **WHEN** user request is received\n  - **THEN** calls shrimp-AGENTS `plan_task` with requirement description\n  - **AND** receives spec document with structured format\n  - **AND** stores projectId for future reference\n\n**US-2.2:** As a **agent-producer**, I want to **analyze requirements to identify scope and complexity**, so that **I can estimate effort accurately**.\n\n- **EARS Criteria:**\n  - **WHEN** spec is created\n  - **THEN** calls shrimp-AGENTS `analyze_task` with spec ID\n  - **AND** receives analysis including: complexity score, estimated duration, required capabilities, suggested agent types\n\n**US-2.3:** As a **agent-producer**, I want to **split specifications into atomic tasks with dependencies**, so that **work can be distributed efficiently**.\n\n- **EARS Criteria:**\n  - **WHEN** analysis is complete\n  - **THEN** calls shrimp-AGENTS `split_tasks` with spec ID\n  - **AND** receives task list where each task has: unique taskId, description, dependencies array, required capabilities, estimated duration\n  - **AND** builds dependency graph for execution ordering\n\n**US-2.4:** As a **user**, I want to **see the breakdown of tasks created from my request**, so that **I understand the implementation plan**.\n\n- **EARS Criteria:**\n  - **WHEN** tasks are created\n  - **THEN** agent-producer posts summary to user's channel\n  - **FORMAT:** \"Created 5 tasks for your spinning color cube:\\n- Task 1: Set up Three.js scene (no dependencies)\\n- Task 2: Create cube geometry (depends on Task 1)\\n- Task 3: Implement random rotation (depends on Task 2)\\n- Task 4: Implement color gradient shader (depends on Task 2)\\n- Task 5: Write tests (depends on Tasks 3, 4)\\n\\nAssigning to 2 agents now...\"\n\n---\n\n### Epic 3: Agent Discovery & Capability Matching\n\n**US-3.1:** As a **agent-producer**, I want to **maintain a registry of available agents and their capabilities**, so that **I can route tasks intelligently**.\n\n- **EARS Criteria:**\n  - **WHEN** agent-producer starts up\n  - **THEN** subscribes to `agents.registry` topic on KÄ€DI broker\n  - **AND** listens for `agents.{agent-name}.capabilities.announce` events\n  - **AND** stores capability registry in memory as Map<agentName, string[]>\n\n**US-3.2:** As a **worker agent**, I want to **announce my capabilities on startup**, so that **producer knows I'm available for work**.\n\n- **EARS Criteria:**\n  - **WHEN** worker agent connects to KÄ€DI broker\n  - **THEN** publishes event to `agents.{self-name}.capabilities.announce`\n  - **PAYLOAD:** `{ agentId, capabilities: [\"webgl\", \"threejs\", \"animation\"], networks: [\"global\", \"frontend\"], status: \"available\" }`\n\n**US-3.3:** As a **agent-producer**, I want to **match tasks to agents based on required capabilities**, so that **work goes to qualified agents only**.\n\n- **EARS Criteria:**\n  - **WHEN** task assignment is needed\n  - **GIVEN** task requires capabilities [\"webgl\", \"animation\"]\n  - **THEN** queries registry for agents with matching capabilities\n  - **AND** selects agent with fewest active tasks (load balancing)\n  - **IF** no matching agent found, THEN queues task and notifies user\n\n---\n\n### Epic 4: Task Distribution\n\n**US-4.1:** As a **agent-producer**, I want to **publish task assignments only when dependencies are satisfied**, so that **agents don't start work prematurely**.\n\n- **EARS Criteria:**\n  - **WHEN** checking task readiness\n  - **GIVEN** task has dependencies [\"task-001\", \"task-002\"]\n  - **IF** all dependencies have status \"completed\"\n  - **THEN** mark task as \"ready\" and publish assignment event\n  - **ELSE** keep task in \"blocked\" state and check again when dependencies update\n\n**US-4.2:** As a **agent-producer**, I want to **publish task assignments to specific agent topics**, so that **KÄ€DI broker routes work correctly**.\n\n- **EARS Criteria:**\n  - **WHEN** task is ready for assignment\n  - **THEN** publishes event to `agents.{target-agent-name}.tasks.assign`\n  - **PAYLOAD:**\n    ```json\n    {\n      \"taskId\": \"task-003\",\n      \"projectId\": \"proj-spinning-cube-123\",\n      \"description\": \"Implement random rotation animation for 3D cube\",\n      \"dependencies\": [\"task-001\", \"task-002\"],\n      \"priority\": \"high\",\n      \"estimatedDuration\": 900,\n      \"requiredCapabilities\": [\"threejs\", \"animation\"],\n      \"artifactRequirements\": {\n        \"codeFiles\": true,\n        \"tests\": true,\n        \"documentation\": false\n      }\n    }\n    ```\n\n**US-4.3:** As a **agent-producer**, I want to **track assignment timestamps and agent acknowledgments**, so that **I can detect stuck tasks**.\n\n- **EARS Criteria:**\n  - **WHEN** task assignment is published\n  - **THEN** records: assignedAt timestamp, targetAgent, status=\"assigned\"\n  - **AND** starts 30-second acknowledgment timeout\n  - **IF** no acknowledgment within 30s, THEN reassigns to different agent\n  - **WHEN** agent acknowledgment received\n  - **THEN** updates status=\"in-progress\", acknowledgedAt timestamp\n\n---\n\n### Epic 5: Task Execution Monitoring\n\n**US-5.1:** As a **worker agent**, I want to **acknowledge task assignments immediately**, so that **producer knows I received the work**.\n\n- **EARS Criteria:**\n  - **WHEN** worker receives assignment on `agents.{self}.tasks.assign`\n  - **THEN** publishes to `agents.producer.tasks.ack`\n  - **PAYLOAD:** `{ taskId, agentId, receivedAt, estimatedCompletion }`\n  - **WITHIN** 5 seconds of receiving assignment\n\n**US-5.2:** As a **worker agent**, I want to **publish heartbeat events during task execution**, so that **producer knows I'm still working**.\n\n- **EARS Criteria:**\n  - **WHEN** task execution is in progress\n  - **THEN** publishes heartbeat every 60 seconds to `agents.producer.tasks.heartbeat`\n  - **PAYLOAD:** `{ taskId, agentId, progress: 45, currentStep: \"Implementing rotation logic\", estimatedCompletion }`\n  - **IF** task takes longer than original estimate, THEN updates estimatedCompletion\n\n**US-5.3:** As a **agent-producer**, I want to **detect stalled tasks via missing heartbeats**, so that **I can intervene when agents fail silently**.\n\n- **EARS Criteria:**\n  - **WHEN** 120 seconds pass without heartbeat\n  - **GIVEN** task status is \"in-progress\"\n  - **THEN** publishes health check request to `agents.{worker-agent}.health.ping`\n  - **IF** no response within 30s, THEN marks task as \"failed\", reassigns to different agent\n  - **AND** notifies user: \"Task 3 stalled on agent1, reassigning to agent2\"\n\n**US-5.4:** As a **user**, I want to **receive progress updates during long-running workflows**, so that **I know work is progressing**.\n\n- **EARS Criteria:**\n  - **WHEN** task starts\n  - **THEN** posts to user's channel: \"ðŸ”„ Task 1/5 started: Set up Three.js scene (frontend-agent)\"\n  - **WHEN** task completes\n  - **THEN** posts: \"âœ… Task 1/5 complete: Three.js scene ready (2m 15s)\"\n  - **WHEN** 50% of tasks complete\n  - **THEN** posts milestone: \"ðŸŽ¯ Halfway done! 3/5 tasks complete, 2 remaining\"\n\n---\n\n### Epic 6: Task Completion & Results Collection\n\n**US-6.1:** As a **worker agent**, I want to **publish completion events with execution results**, so that **producer can track deliverables**.\n\n- **EARS Criteria:**\n  - **WHEN** task implementation is done and tested\n  - **THEN** calls shrimp-AGENTS `execute_task` to log implementation details\n  - **AND** publishes to `agents.producer.tasks.completed`\n  - **PAYLOAD:**\n    ```json\n    {\n      \"taskId\": \"task-001\",\n      \"agentId\": \"frontend-agent\",\n      \"completedAt\": \"2025-11-30T03:45:00Z\",\n      \"duration\": 135,\n      \"status\": \"success\",\n      \"artifacts\": {\n        \"files\": [\"src/scene/ThreeScene.ts\", \"src/scene/SceneManager.ts\"],\n        \"linesAdded\": 245,\n        \"linesRemoved\": 12,\n        \"testsAdded\": 8,\n        \"testsPassed\": 8\n      },\n      \"notes\": \"Set up Three.js scene with WebGL renderer, camera, and lighting\"\n    }\n    ```\n\n**US-6.2:** As a **agent-producer**, I want to **update dependency graph when tasks complete**, so that **blocked tasks can start immediately**.\n\n- **EARS Criteria:**\n  - **WHEN** completion event received for task-001\n  - **THEN** updates task-001 status to \"completed\"\n  - **AND** queries dependency graph for tasks waiting on task-001\n  - **FOR EACH** dependent task: checks if all dependencies now satisfied\n  - **IF** all satisfied, THEN publishes assignment for dependent task\n  - **WITHIN** 5 seconds of receiving completion event\n\n**US-6.3:** As a **agent-producer**, I want to **aggregate task results by project**, so that **I can present comprehensive deliverables to user**.\n\n- **EARS Criteria:**\n  - **WHEN** all tasks for project reach \"completed\" status\n  - **THEN** collects all artifacts from completion events\n  - **AND** generates project summary:\n    - Total duration\n    - Files modified/created (grouped by category)\n    - Test coverage statistics\n    - Agent contributions (work distribution)\n  - **AND** prepares for verification phase\n\n---\n\n### Epic 7: Verification & Quality Assurance\n\n**US-7.1:** As a **agent-producer**, I want to **verify each completed task against acceptance criteria**, so that **quality standards are met**.\n\n- **EARS Criteria:**\n  - **WHEN** task completion event received\n  - **THEN** calls shrimp-AGENTS `verify_task` with taskId\n  - **AND** receives verification result: score (0-100), passed criteria, failed criteria, recommendations\n  - **IF** score < 80, THEN marks task as \"needs-revision\"\n  - **AND** creates remediation task with failed criteria details\n  - **IF** score >= 80, THEN accepts task completion\n\n**US-7.2:** As a **agent-producer**, I want to **perform project-level verification after all tasks complete**, so that **integration issues are caught**.\n\n- **EARS Criteria:**\n  - **WHEN** all individual tasks pass verification (score >= 80)\n  - **THEN** calls shrimp-AGENTS with aggregated project context\n  - **CHECKS:**\n    - All requirements from original spec are addressed\n    - No conflicting implementations between tasks\n    - Integration points between tasks work correctly\n    - Code style consistency across tasks\n  - **IF** project verification fails, THEN creates integration fix tasks\n  - **ELSE** proceeds to user notification\n\n**US-7.3:** As a **user**, I want to **receive verification results before final review**, so that **I know quality has been checked**.\n\n- **EARS Criteria:**\n  - **WHEN** project verification passes\n  - **THEN** posts summary to user's channel:\n    ```\n    âœ… All tasks completed and verified!\n\n    ðŸ“Š Project Summary:\n    - 5 tasks completed in 12 minutes\n    - 8 files created/modified\n    - 427 lines of code added\n    - 15 tests added (all passing)\n    - Quality score: 92/100\n\n    ðŸŽ¯ Deliverables:\n    - Three.js scene with spinning cube\n    - Random rotation animation\n    - Smooth color gradient shader\n    - Full test coverage\n\n    Ready for your review!\n    ```\n\n---\n\n### Epic 8: Failure Handling & Recovery\n\n**US-8.1:** As a **agent-producer**, I want to **detect task failures from worker agents**, so that **I can take corrective action**.\n\n- **EARS Criteria:**\n  - **WHEN** worker publishes to `agents.producer.tasks.failed`\n  - **OR** heartbeat timeout occurs (120s without update)\n  - **OR** acknowledgment timeout occurs (30s after assignment)\n  - **THEN** marks task status as \"failed\"\n  - **AND** records failure reason and failed agent\n\n**US-8.2:** As a **agent-producer**, I want to **automatically reassign failed tasks to different agents**, so that **single agent failures don't block projects**.\n\n- **EARS Criteria:**\n  - **WHEN** task fails on agent1\n  - **THEN** queries capability registry for alternative agents\n  - **IF** alternative found, THEN reassigns with priority=\"high\", retry attempt count\n  - **AND** adds failure context to assignment payload\n  - **IF** no alternative, THEN notifies user for manual intervention\n\n**US-8.3:** As a **agent-producer**, I want to **limit retry attempts per task**, so that **infinite loops are prevented**.\n\n- **EARS Criteria:**\n  - **WHEN** task fails for 3rd time (configurable)\n  - **THEN** marks task as \"permanently-failed\"\n  - **AND** halts dependent tasks\n  - **AND** notifies user: \"âš ï¸ Task 3 failed after 3 attempts. Manual intervention needed.\"\n  - **AND** provides failure diagnostics from all attempts\n\n**US-8.4:** As a **user**, I want to **be notified of failures with actionable context**, so that **I can help resolve issues**.\n\n- **EARS Criteria:**\n  - **WHEN** task is reassigned due to failure\n  - **THEN** posts to user's channel: \"âš ï¸ Task 2 failed on agent1 (timeout), reassigning to agent2...\"\n  - **WHEN** task permanently fails\n  - **THEN** posts detailed failure report with logs, attempted fixes, suggested next steps\n\n---\n\n### Epic 9: Multi-Channel User Experience\n\n**US-9.1:** As a **agent-producer**, I want to **remember which channel user submitted request from**, so that **responses go to correct location**.\n\n- **EARS Criteria:**\n  - **WHEN** request received via Slack thread\n  - **THEN** stores userContext: `{ userId, channel: \"slack\", threadId, channelId: \"#project-updates\" }`\n  - **AND** all subsequent messages use same context for publishing\n\n**US-9.2:** As a **user**, I want to **receive all project updates in the same channel I initiated request**, so that **conversation stays coherent**.\n\n- **EARS Criteria:**\n  - **WHEN** task status updates occur\n  - **THEN** agent-producer publishes to stored userContext.channel and userContext.threadId\n  - **MAINTAINS** threaded conversation in Slack/Discord\n  - **MAINTAINS** session continuity in Claude Desktop/Code\n\n**US-9.3:** As a **user using Claude Desktop**, I want to **see rich formatted output with code blocks and markdown**, so that **results are readable**.\n\n- **EARS Criteria:**\n  - **WHEN** userContext.channel === \"claude-desktop\"\n  - **THEN** formats messages with markdown syntax, code fences, tables\n  - **EXAMPLE:**\n    ```markdown\n    ## Task 1 Complete: Three.js Scene Setup\n\n    **Files Created:**\n    - `src/scene/ThreeScene.ts` (145 lines)\n    - `src/scene/SceneManager.ts` (100 lines)\n\n    **Key Functions:**\n    \\```typescript\n    initScene(container: HTMLElement): Scene\n    setupRenderer(width: number, height: number): WebGLRenderer\n    \\```\n    ```\n\n**US-9.4:** As a **user using Slack**, I want to **see concise updates with emoji indicators**, so that **I can scan status quickly**.\n\n- **EARS Criteria:**\n  - **WHEN** userContext.channel === \"slack\"\n  - **THEN** uses Slack block kit formatting\n  - **AND** includes emoji status indicators: ðŸ”„ (in-progress), âœ… (complete), âš ï¸ (warning), âŒ (failed)\n  - **LIMITS** message length to avoid Slack truncation\n\n---\n\n## 3. Functional Requirements\n\n### FR-1: MCP Client Integration\n- **FR-1.1:** agent-producer MUST establish WebSocket or STDIO connection to shrimp-AGENTS MCP server on startup\n- **FR-1.2:** Connection MUST implement automatic reconnection with exponential backoff (1s, 2s, 4s, 8s, max 30s)\n- **FR-1.3:** MCP calls MUST timeout after 30 seconds with retry capability\n- **FR-1.4:** All MCP operations MUST include projectId for multi-tenancy support\n\n### FR-2: Task Decomposition\n- **FR-2.1:** Task splitting MUST produce tasks where each touches 1-5 files maximum (atomic units)\n- **FR-2.2:** Dependency graph MUST be acyclic (detect cycles and reject invalid plans)\n- **FR-2.3:** Each task MUST include: unique ID, description, dependencies, required capabilities, estimated duration, acceptance criteria\n- **FR-2.4:** Total task count per project SHOULD be 3-20 (warn if >20, suggest splitting into sub-projects)\n\n### FR-3: Agent Registry\n- **FR-3.1:** Registry MUST track: agent ID, capabilities (string[]), status (available/busy/offline), last heartbeat, active task count\n- **FR-3.2:** Agents absent for >300s MUST be marked \"offline\" and removed from assignment pool\n- **FR-3.3:** Registry MUST support capability queries with AND/OR logic (e.g., \"webgl AND (threejs OR babylonjs)\")\n\n### FR-4: Event Publishing\n- **FR-4.1:** All events MUST follow topic pattern: `agents.{target}.{category}.{action}`\n- **FR-4.2:** Event payloads MUST be valid JSON with required fields validated via Zod schemas\n- **FR-4.3:** Critical events (assignment, completion, failure) MUST use QoS level 1 (at-least-once delivery) if KÄ€DI supports it\n- **FR-4.4:** Events MUST include correlation ID for distributed tracing\n\n### FR-5: Monitoring & Timeouts\n- **FR-5.1:** Heartbeat interval: 60 seconds (configurable via env: HEARTBEAT_INTERVAL_MS)\n- **FR-5.2:** Heartbeat timeout: 120 seconds (2 missed heartbeats triggers health check)\n- **FR-5.3:** Acknowledgment timeout: 30 seconds (task reassigned if no ack)\n- **FR-5.4:** Task execution timeout: configurable per-task based on estimated duration * 2\n\n### FR-6: Verification\n- **FR-6.1:** Task verification MUST occur immediately after completion event received\n- **FR-6.2:** Verification score threshold: 80/100 (configurable via env: MIN_VERIFICATION_SCORE)\n- **FR-6.3:** Failed verification MUST create remediation task with specific failure criteria\n- **FR-6.4:** Project-level verification MUST aggregate individual task scores and check integration\n\n### FR-7: Failure Recovery\n- **FR-7.1:** Maximum retry attempts per task: 3 (configurable via env: MAX_TASK_RETRIES)\n- **FR-7.2:** Reassignment MUST exclude agents that previously failed the same task\n- **FR-7.3:** Permanent failure MUST block dependent tasks and notify user\n- **FR-7.4:** Failure context MUST include: error message, stack trace, agent logs, attempted fixes\n\n### FR-8: State Management\n- **FR-8.1:** Producer MUST maintain in-memory state for active projects: projectId â†’ { tasks, assignments, userContext }\n- **FR-8.2:** State MUST persist to shrimp-AGENTS for durability (survives producer restarts)\n- **FR-8.3:** State synchronization MUST occur after every task status change\n- **FR-8.4:** Stale projects (no activity for >24h) SHOULD be archived\n\n---\n\n## 4. Non-Functional Requirements\n\n### NFR-1: Performance\n- **NFR-1.1:** Task assignment latency MUST be <2 seconds from completion event to dependent task assignment\n- **NFR-1.2:** Producer MUST handle 10 concurrent projects without degradation\n- **NFR-1.3:** Event processing throughput MUST support 100 events/second\n- **NFR-1.4:** Memory usage MUST stay <500MB for 10 active projects\n\n### NFR-2: Reliability\n- **NFR-2.1:** Producer uptime MUST be >99% (automatic restart on crashes)\n- **NFR-2.2:** MCP connection loss MUST NOT lose task state (queued operations on reconnect)\n- **NFR-2.3:** Event delivery failures MUST trigger retries (exponential backoff, max 5 attempts)\n- **NFR-2.4:** Data corruption MUST be prevented via validation schemas on all payloads\n\n### NFR-3: Scalability\n- **NFR-3.1:** Architecture MUST support horizontal scaling (multiple producer instances with leader election)\n- **NFR-3.2:** Agent registry MUST scale to 100 worker agents\n- **NFR-3.3:** Event topic structure MUST support namespacing for multi-tenancy\n\n### NFR-4: Observability\n- **NFR-4.1:** All events MUST be logged with timestamps, correlation IDs, and payloads\n- **NFR-4.2:** Metrics MUST be exposed: active projects, task completion rate, failure rate, agent utilization\n- **NFR-4.3:** Distributed tracing MUST be supported via OpenTelemetry spans\n- **NFR-4.4:** Health check endpoint MUST expose: connection status (MCP, KÄ€DI), active tasks, memory usage\n\n### NFR-5: Usability\n- **NFR-5.1:** User messages MUST use non-technical language (avoid terms like \"taskId\", \"payload\", \"broker\")\n- **NFR-5.2:** Error messages MUST suggest actionable next steps\n- **NFR-5.3:** Progress indicators MUST show percentage completion and ETA\n- **NFR-5.4:** Final summaries MUST highlight deliverables in user-friendly format\n\n---\n\n## 5. Constraints\n\n### Technical Constraints\n- **TC-1:** MUST use existing KÄ€DI broker infrastructure (no alternative message brokers)\n- **TC-2:** MUST use shrimp-AGENTS MCP server as single source of truth for task state\n- **TC-3:** MUST be implemented in TypeScript (consistent with template-agent-typescript)\n- **TC-4:** MUST use @kadi.build/core SDK for all KÄ€DI interactions\n- **TC-5:** MUST use @modelcontextprotocol/sdk for all MCP interactions\n\n### Environmental Constraints\n- **EC-1:** Node.js version: >=18.0.0\n- **EC-2:** shrimp-AGENTS MCP server MUST be running and accessible\n- **EC-3:** KÄ€DI broker MUST be running and accessible\n- **EC-4:** Worker agents MUST be running to execute tasks\n\n### Business Constraints\n- **BC-1:** Initial release MUST support 4 channels: Claude Desktop, Claude Code, Slack, Discord\n- **BC-2:** MUST NOT introduce breaking changes to existing worker agents\n- **BC-3:** MUST be operational with as few as 1 worker agent (graceful degradation)\n\n---\n\n## 6. Acceptance Criteria\n\n### Overall Acceptance\n- [ ] **AC-1:** User can submit request via any supported channel and receive appropriate acknowledgment\n- [ ] **AC-2:** Request is decomposed into tasks via shrimp-AGENTS with dependency graph\n- [ ] **AC-3:** Tasks are assigned to capable agents based on registry matching\n- [ ] **AC-4:** User receives progress updates at task start and completion\n- [ ] **AC-5:** Task failures trigger automatic reassignment up to 3 times\n- [ ] **AC-6:** All completed tasks pass verification (score >= 80)\n- [ ] **AC-7:** User receives final summary with deliverables and quality score\n- [ ] **AC-8:** System handles MCP or KÄ€DI connection loss without data loss\n\n### Example Workflow Acceptance (Spinning Cube)\n- [ ] **AC-E1:** User sends \"Can you create a design document to make a cube spinning randomly and changes color gradually?\" via Slack\n- [ ] **AC-E2:** agent-producer responds in Slack thread within 2 seconds with acknowledgment\n- [ ] **AC-E3:** Tasks are created: Scene setup, Cube geometry, Rotation animation, Color shader, Tests\n- [ ] **AC-E4:** Tasks assigned to frontend-agent and test-agent based on capabilities\n- [ ] **AC-E5:** User receives 5 progress updates (one per task start) and 5 completion confirmations\n- [ ] **AC-E6:** If frontend-agent fails during rotation task, task is reassigned to backup agent\n- [ ] **AC-E7:** All tasks complete within estimated time (Â±50%)\n- [ ] **AC-E8:** Verification confirms: scene renders, cube spins randomly, colors transition smoothly, all tests pass\n- [ ] **AC-E9:** User receives Slack message with summary, file list, and quality score\n- [ ] **AC-E10:** User can access implementation artifacts through provided links\n\n---\n\n## 7. Dependencies\n\n### Internal Dependencies\n- **ID-1:** @agents/shared (base bot functionality, event publisher)\n- **ID-2:** @kadi.build/core (KÄ€DI client, event schemas)\n- **ID-3:** template-agent-typescript structure (agent initialization patterns)\n\n### External Dependencies\n- **ED-1:** shrimp-AGENTS MCP server (plan_task, analyze_task, split_tasks, execute_task, verify_task tools)\n- **ED-2:** KÄ€DI broker (event routing, topic subscriptions)\n- **ED-3:** Worker agents (must implement task execution protocol)\n- **ED-4:** Channel integrations (Slack API, Discord API, Claude Desktop/Code protocols)\n\n### MCP Tool Dependencies\nThe following shrimp-AGENTS MCP tools are required:\n- `plan_task` - Create project specification from user requirement\n- `analyze_task` - Analyze spec for complexity and required capabilities\n- `split_tasks` - Break spec into atomic tasks with dependencies\n- `execute_task` - Log task implementation details\n- `verify_task` - Verify task completion against criteria\n- `list_tasks` - Query current task status for project\n- `get_task_detail` - Retrieve detailed task information\n\n---\n\n## 8. Out of Scope\n\nThe following are explicitly **NOT** included in this initial release:\n- **OOS-1:** Multi-producer instances with leader election (future: horizontal scaling)\n- **OOS-2:** Task prioritization based on business value (all tasks equal priority initially)\n- **OOS-3:** Cost tracking and budget constraints per project\n- **OOS-4:** Machine learning for capability matching optimization\n- **OOS-5:** User approval workflows before task execution starts (auto-execute initially)\n- **OOS-6:** Rollback functionality for failed projects\n- **OOS-7:** Scheduled/deferred task execution\n- **OOS-8:** Cross-project dependency management\n- **OOS-9:** Agent performance analytics and recommendations\n- **OOS-10:** Custom verification criteria per user/project\n\n---\n\n## 9. Risks & Mitigations\n\n| Risk | Impact | Probability | Mitigation |\n|------|---------|-------------|------------|\n| **R-1:** shrimp-AGENTS MCP server becomes unavailable during project execution | **High** - Blocks all task operations | **Medium** | Implement request queuing with 30s retry, degrade gracefully by caching last known task state |\n| **R-2:** KÄ€DI broker message loss due to network issues | **High** - Tasks never assigned or completed events lost | **Low** | Use persistent event log, implement ack/nack protocol, retry assignments after timeout |\n| **R-3:** Circular dependencies in task graph | **Medium** - Project stuck, no tasks can start | **Low** | Validate acyclic graph before assignment, reject invalid specs with error message to user |\n| **R-4:** All worker agents go offline during execution | **High** - Project cannot complete | **Medium** | Detect zero available agents, pause project, notify user, resume when agents return |\n| **R-5:** Task verification always fails due to overly strict criteria | **Medium** - Infinite remediation loop | **Low** | Implement max remediation attempts (3), escalate to user for manual review after 3 failures |\n| **R-6:** Thundering herd when many tasks unblock simultaneously | **Low** - Temporary slowdown | **Medium** | Rate limit task assignments (max 5/second), queue excess for delayed publishing |\n| **R-7:** Memory leak from tracking too many completed projects | **Medium** - Producer crashes after days of operation | **Medium** | Implement auto-archival of projects inactive >24h, periodic garbage collection |\n| **R-8:** User submits malicious input to crash producer | **High** - Service disruption | **Low** | Validate all user input with strict schemas, sanitize before passing to MCP tools, implement circuit breaker |\n\n---\n\n## 10. Success Metrics\n\n### Quantitative Metrics\n- **SM-1:** **Task Assignment Latency:** <2 seconds from dependency satisfaction to assignment published\n- **SM-2:** **Task Completion Rate:** >90% of assigned tasks complete successfully without manual intervention\n- **SM-3:** **Verification Pass Rate:** >85% of tasks pass verification on first attempt\n- **SM-4:** **End-to-End Project Duration:** Actual duration within Â±50% of estimated duration\n- **SM-5:** **User Satisfaction Response Time:** User receives acknowledgment within 2 seconds of request\n- **SM-6:** **System Uptime:** Producer available >99% of measurement period\n\n### Qualitative Metrics\n- **SM-7:** **User Experience:** Users report \"easy to use\" and \"clear progress visibility\" in feedback\n- **SM-8:** **Code Quality:** Implementation artifacts pass existing code review standards (linting, type safety)\n- **SM-9:** **Documentation Quality:** Users can understand deliverables without asking for clarification\n\n### Business Metrics\n- **SM-10:** **Adoption Rate:** At least 5 distinct users submit projects via producer within first month\n- **SM-11:** **Repeat Usage:** Users who complete 1 project submit average of 2+ additional projects\n- **SM-12:** **Channel Distribution:** Usage balanced across all 4 supported channels (no single channel >60%)\n\n---\n\n## 11. Glossary\n\n- **agent-producer:** The orchestrator agent being developed in this spec, responsible for coordinating multi-agent workflows\n- **worker agent:** Any agent that executes tasks assigned by producer (e.g., frontend-agent, backend-agent, test-agent)\n- **shrimp-AGENTS:** MCP server providing centralized task/spec management tools\n- **KÄ€DI broker:** Event-driven message broker for agent communication\n- **MCP (Model Context Protocol):** Protocol for AI agent tool integration\n- **Task:** Atomic unit of work (1-5 files) with clear acceptance criteria\n- **Project:** Collection of related tasks created from single user request\n- **Dependency graph:** Directed acyclic graph showing task execution order\n- **Capability:** Skill or technology an agent can work with (e.g., \"threejs\", \"postgresql\")\n- **Heartbeat:** Periodic status update from worker agent indicating active execution\n- **Verification score:** 0-100 numeric assessment of task completion quality\n- **Remediation task:** New task created to fix failed verification criteria\n- **User context:** Stored information about request origin (channel, user ID, thread ID)\n\n---\n\n**End of Requirements Document**\n",
  "fileStats": {
    "size": 31237,
    "lines": 614,
    "lastModified": "2025-11-30T09:25:23.700Z"
  },
  "comments": []
}