{
  "id": "snapshot_1765136221898_2mtgjfcaz",
  "approvalId": "approval_1765128857521_54po408hn",
  "approvalTitle": "Design Document - Revised (Redis + Path Corrections)",
  "version": 3,
  "timestamp": "2025-12-07T19:37:01.898Z",
  "trigger": "approved",
  "status": "pending",
  "content": "# Design Document\r\n\r\n## Overview\r\n\r\nThis design document outlines the technical architecture for enhancing `template-agent-typescript` with four major capabilities:\r\n\r\n1. **Multi-LLM Provider System**: Pluggable provider architecture supporting Anthropic Claude and OpenAI-compatible Model Manager Gateway\r\n2. **Autonomous Infrastructure Management**: Self-deployment capabilities using deploy-ability library to Digital Ocean\r\n3. **Hybrid Memory System**: Multi-layered memory using file-based storage (JSON/MD) for short-term conversation context and ArcadeDB for long-term persistent storage\r\n4. **Comprehensive File Management**: Integration of four file management abilities via KADI MCP protocol\r\n\r\nThe design follows a modular, service-oriented architecture where each capability is implemented as an independent service with clean interfaces, enabling the agent to function even if specific subsystems fail (graceful degradation).\r\n\r\n## Steering Document Alignment\r\n\r\n### Technical Standards (tech.md)\r\n\r\n**Not applicable** - No steering documents exist for this project. The design follows KADI ecosystem patterns:\r\n\r\n- **MCP Protocol Integration**: File abilities accessed via KADI broker MCP protocol, not direct imports\r\n- **Result Type Pattern**: All async operations return `Result<T, E>` for predictable error handling\r\n- **Service Layer Architecture**: Clear separation between provider adapters, memory services, and bot logic\r\n- **Event-Driven Communication**: KADI events for bot mentions, tool invocations, and system notifications\r\n\r\n### Project Structure (structure.md)\r\n\r\n**Not applicable** - No steering documents exist. The design extends the existing template structure:\r\n\r\n```\r\ntemplate-agent-typescript/\r\n├── src/\r\n│   ├── index.ts                    # Main entry point (existing)\r\n│   ├── providers/                  # NEW: LLM provider system\r\n│   │   ├── base-provider.ts        # Provider interface\r\n│   │   ├── anthropic-provider.ts   # Existing Anthropic integration\r\n│   │   ├── model-manager-provider.ts # NEW: OpenAI-compatible gateway\r\n│   │   └── provider-manager.ts     # Provider orchestration & fallback\r\n│   ├── memory/                     # NEW: Hybrid memory system\r\n│   │   ├── memory-service.ts       # Core memory service (orchestrates file + ArcadeDB)\r\n│   │   ├── file-storage-adapter.ts # File-based storage for short-term memory (JSON/MD)\r\n│   │   ├── arcadedb-adapter.ts     # ArcadeDB integration for long-term memory\r\n│   │   └── types.ts                # Memory data models\r\n│   ├── data/                       # NEW: Memory data directory\r\n│   │   └── memory/                 # JSON files for conversation context\r\n│   │       ├── {userId}/\r\n│   │       │   ├── {channelId}.json  # Conversation messages\r\n│   │       │   └── preferences.json  # User preferences\r\n│   │       └── public/\r\n│   │           └── knowledge.json    # Shared knowledge\r\n│   ├── deployment/                 # NEW: Self-deployment system\r\n│   │   ├── deploy-service.ts       # Deployment orchestration\r\n│   │   └── digital-ocean-config.ts # Deployment configuration\r\n│   ├── bot/                        # Existing bot implementations\r\n│   │   ├── slack-bot.ts            # Enhanced with memory & multi-LLM\r\n│   │   └── discord-bot.ts          # Enhanced with memory & multi-LLM\r\n│   └── tools/                      # Existing KADI tools\r\n├── .env                            # Configuration (enhanced)\r\n└── package.json                    # Dependencies (enhanced)\r\n```\r\n\r\n## Code Reuse Analysis\r\n\r\n### Existing Components to Leverage\r\n\r\n- **KadiClient**: Broker connection, tool registration, event pub/sub\r\n  - *How it will be used*: Access file management abilities via `client.load()` and `protocol.invokeTool()`\r\n  - *Location*: `@kadi.build/core`\r\n\r\n- **BaseBot**: Circuit breaker, retry logic, metrics collection, tool discovery\r\n  - *How it will be used*: Extended by SlackBot and DiscordBot, provides resilience patterns\r\n  - *Location*: `C:\\p4\\Personal\\SD\\agents-library\\src\\base-bot.ts`\r\n\r\n- **ConversationManager**: Claude API multi-turn conversation handling\r\n  - *How it will be extended*: Add provider selection logic, route to Anthropic or Model Manager\r\n  - *Location*: `C:\\p4\\Personal\\SD\\agents-library\\src\\conversation-manager.ts`\r\n\r\n- **ToolExecutor**: KADI tool execution with retry and error handling\r\n  - *How it will be used*: Execute file operations through broker MCP protocol\r\n  - *Location*: `C:\\p4\\Personal\\SD\\agents-library\\src\\tool-executor.ts`\r\n\r\n- **Anthropic SDK Integration**: Currently hardcoded in index.ts (lines 208-229)\r\n  - *How it will be refactored*: Extract to `AnthropicProvider` class implementing `LLMProvider` interface\r\n\r\n### Integration Points\r\n\r\n- **KADI Broker MCP Protocol**: File abilities accessed via broker, not direct package imports\r\n  - *Integration*: Use `client.getBrokerProtocol().invokeTool()` pattern already established in index.ts (lines 310-318)\r\n\r\n- **Environment Variables**: Extend existing configuration in `.env`\r\n  - *Integration*: Add `MODEL_MANAGER_BASE_URL`, `MODEL_MANAGER_API_KEY`, `MEMORY_DATA_PATH`, `ARCADEDB_URL` to existing config\r\n\r\n- **Slack/Discord Bot Event Handlers**: Enhance existing bot implementations\r\n  - *Integration*: Inject MemoryService and ProviderManager into bot constructors\r\n\r\n## Architecture\r\n\r\n### High-Level System Architecture\r\n\r\n```mermaid\r\ngraph TB\r\n    subgraph \"User Interfaces\"\r\n        Slack[Slack Messages]\r\n        Discord[Discord Messages]\r\n    end\r\n\r\n    subgraph \"Bot Layer\"\r\n        SlackBot[SlackBot]\r\n        DiscordBot[DiscordBot]\r\n    end\r\n\r\n    subgraph \"Intelligence Layer\"\r\n        PM[ProviderManager]\r\n        AP[AnthropicProvider]\r\n        MMP[ModelManagerProvider]\r\n    end\r\n\r\n    subgraph \"Memory Layer\"\r\n        MS[MemoryService]\r\n        FS[File Storage<br/>JSON/MD Files]\r\n        ADB[(ArcadeDB)]\r\n    end\r\n\r\n    subgraph \"File Operations Layer\"\r\n        FM[File Manager Proxy]\r\n        LRFM[local-remote-file-manager]\r\n        CFM[cloud-file-manager]\r\n        CRA[container-registry]\r\n        FMA[file-management]\r\n    end\r\n\r\n    subgraph \"Deployment Layer\"\r\n        DS[DeployService]\r\n        DA[deploy-ability]\r\n        DO[Digital Ocean]\r\n    end\r\n\r\n    Slack --> SlackBot\r\n    Discord --> DiscordBot\r\n    SlackBot --> PM\r\n    DiscordBot --> PM\r\n    SlackBot --> MS\r\n    DiscordBot --> MS\r\n    PM --> AP\r\n    PM --> MMP\r\n    MMP --> ModelManager[Model Manager Gateway]\r\n    MS --> FS\r\n    MS --> ADB\r\n    SlackBot --> FM\r\n    DiscordBot --> FM\r\n    FM --> LRFM\r\n    FM --> CFM\r\n    FM --> CRA\r\n    FM --> FMA\r\n    DS --> DA\r\n    DA --> DO\r\n\r\n    style PM fill:#4A90E2\r\n    style MS fill:#9B59B6\r\n    style FM fill:#50C878\r\n    style DS fill:#FF6B6B\r\n```\r\n\r\n### Modular Design Principles\r\n\r\n- **Single File Responsibility**: Each provider/service in separate file with single concern\r\n- **Component Isolation**: Memory, providers, deployment are independent modules with no cross-dependencies\r\n- **Service Layer Separation**:\r\n  - **Bot Layer**: Handles platform-specific events (Slack/Discord)\r\n  - **Intelligence Layer**: Routes LLM requests to appropriate provider\r\n  - **Memory Layer**: Persists and retrieves conversation context\r\n  - **Operations Layer**: File and deployment capabilities\r\n- **Utility Modularity**: Provider manager, memory service, deployment service are reusable across different bot implementations\r\n\r\n### Provider Selection Flow\r\n\r\n```mermaid\r\nsequenceDiagram\r\n    participant User\r\n    participant SlackBot\r\n    participant ProviderManager\r\n    participant AnthropicProvider\r\n    participant ModelManagerProvider\r\n    participant MemoryService\r\n\r\n    User->>SlackBot: \"@bot What is 2+2?\"\r\n    SlackBot->>MemoryService: retrieveContext(userId, channelId)\r\n    MemoryService-->>SlackBot: contextMessages[]\r\n    SlackBot->>ProviderManager: generateResponse(messages, model?)\r\n\r\n    alt model specified\r\n        ProviderManager->>ProviderManager: detectProvider(model)\r\n    else no model specified\r\n        ProviderManager->>ProviderManager: usePrimaryProvider()\r\n    end\r\n\r\n    alt Anthropic provider selected\r\n        ProviderManager->>AnthropicProvider: chat(messages)\r\n        AnthropicProvider-->>ProviderManager: response\r\n    else Model Manager provider selected\r\n        ProviderManager->>ModelManagerProvider: chat(messages)\r\n        ModelManagerProvider-->>ProviderManager: response\r\n    end\r\n\r\n    alt provider failed\r\n        ProviderManager->>ProviderManager: tryFallbackProvider()\r\n    end\r\n\r\n    ProviderManager-->>SlackBot: response\r\n    SlackBot->>MemoryService: storeMessage(userMsg, botMsg)\r\n    SlackBot-->>User: Response\r\n```\r\n\r\n## Components and Interfaces\r\n\r\n### Component 1: LLMProvider Interface\r\n\r\n- **Purpose:** Define standard interface for all LLM provider adapters (Anthropic, Model Manager)\r\n- **Interfaces:**\r\n  ```typescript\r\n  interface LLMProvider {\r\n    name: string;\r\n    chat(messages: Message[], options?: ChatOptions): Promise<Result<string, ProviderError>>;\r\n    streamChat(messages: Message[], options?: ChatOptions): Promise<Result<AsyncIterator<string>, ProviderError>>;\r\n    isHealthy(): Promise<boolean>;\r\n    getAvailableModels(): Promise<Result<string[], ProviderError>>;\r\n  }\r\n\r\n  interface ChatOptions {\r\n    model?: string;\r\n    maxTokens?: number;\r\n    temperature?: number;\r\n    tools?: Tool[];\r\n  }\r\n\r\n  interface Message {\r\n    role: 'user' | 'assistant' | 'system';\r\n    content: string;\r\n  }\r\n\r\n  type Result<T, E> = { success: true; data: T } | { success: false; error: E };\r\n  ```\r\n- **Dependencies:** None (pure interface)\r\n- **Reuses:** None (new component)\r\n\r\n### Component 2: AnthropicProvider\r\n\r\n- **Purpose:** Adapter for Anthropic Claude API implementing LLMProvider interface\r\n- **Interfaces:** Implements `LLMProvider`\r\n- **Dependencies:** `@anthropic-ai/sdk`, environment variable `ANTHROPIC_API_KEY`\r\n- **Reuses:** Existing Anthropic SDK usage pattern from `index.ts` lines 208-229\r\n\r\n### Component 3: ModelManagerProvider\r\n\r\n- **Purpose:** Adapter for OpenAI-compatible Model Manager Gateway\r\n- **Interfaces:** Implements `LLMProvider`\r\n- **Dependencies:**\r\n  - Environment variables: `MODEL_MANAGER_BASE_URL`, `MODEL_MANAGER_API_KEY`\r\n  - HTTP client (fetch or axios)\r\n- **Reuses:** None (new component)\r\n- **Implementation Details:**\r\n  ```typescript\r\n  class ModelManagerProvider implements LLMProvider {\r\n    name = 'model-manager';\r\n    private baseURL: string;\r\n    private apiKey: string;\r\n\r\n    async chat(messages: Message[], options?: ChatOptions): Promise<Result<string, ProviderError>> {\r\n      const response = await fetch(`${this.baseURL}/v1/chat/completions`, {\r\n        method: 'POST',\r\n        headers: {\r\n          'Authorization': `Bearer ${this.apiKey}`,\r\n          'Content-Type': 'application/json'\r\n        },\r\n        body: JSON.stringify({\r\n          model: options?.model || 'gpt-4o-mini',\r\n          messages: messages.map(m => ({ role: m.role, content: m.content })),\r\n          max_tokens: options?.maxTokens,\r\n          temperature: options?.temperature,\r\n          tools: options?.tools\r\n        })\r\n      });\r\n\r\n      if (!response.ok) {\r\n        return { success: false, error: { code: response.status, message: await response.text() } };\r\n      }\r\n\r\n      const data = await response.json();\r\n      return { success: true, data: data.choices[0].message.content };\r\n    }\r\n  }\r\n  ```\r\n\r\n### Component 4: ProviderManager\r\n\r\n- **Purpose:** Orchestrate provider selection, health checking, and automatic fallback\r\n- **Interfaces:**\r\n  ```typescript\r\n  class ProviderManager {\r\n    constructor(providers: LLMProvider[], config: ProviderConfig);\r\n    async chat(messages: Message[], model?: string): Promise<Result<string, ProviderError>>;\r\n    async streamChat(messages: Message[], model?: string): Promise<Result<AsyncIterator<string>, ProviderError>>;\r\n    getHealthStatus(): Promise<Map<string, boolean>>;\r\n    private selectProvider(model?: string): LLMProvider;\r\n    private handleProviderFailure(provider: LLMProvider, error: ProviderError): Promise<Result<string, ProviderError>>;\r\n  }\r\n\r\n  interface ProviderConfig {\r\n    primaryProvider: string;      // 'anthropic' or 'model-manager'\r\n    fallbackProvider?: string;     // Optional fallback\r\n    retryAttempts: number;\r\n    retryDelayMs: number;\r\n    healthCheckIntervalMs: number;\r\n  }\r\n  ```\r\n- **Dependencies:** All registered `LLMProvider` implementations\r\n- **Reuses:** BaseBot's retry logic patterns\r\n\r\n### Component 5: MemoryService\r\n\r\n- **Purpose:** Hybrid memory orchestration using file-based storage (JSON/MD) for short-term memory and ArcadeDB for persistent long-term storage\r\n- **Architecture:**\r\n  - **File Storage Layer**: JSON files for active conversation context (last 20 messages per channel)\r\n  - **ArcadeDB Layer**: Persistent storage for summarized history, user preferences, and public knowledge\r\n  - **Handoff Mechanism**: When short-term memory exceeds threshold (20 messages), oldest messages are summarized by LLM and archived to ArcadeDB, then removed from JSON file\r\n- **Interfaces:**\r\n  ```typescript\r\n  class MemoryService {\r\n    constructor(memoryDataPath: string, arcadedbUrl: string);\r\n\r\n    // Short-term memory (conversation context - stored in JSON files)\r\n    async storeMessage(userId: string, channelId: string, message: Message): Promise<Result<void, MemoryError>>;\r\n    async retrieveContext(userId: string, channelId: string, limit?: number): Promise<Result<Message[], MemoryError>>;\r\n\r\n    // Long-term memory (summarized history - stored in ArcadeDB)\r\n    async summarizeAndArchive(userId: string, channelId: string): Promise<Result<void, MemoryError>>;\r\n    async searchLongTerm(userId: string, query: string): Promise<Result<MemoryEntry[], MemoryError>>;\r\n\r\n    // Private memory (user preferences - stored in JSON files)\r\n    async storePreference(userId: string, key: string, value: any): Promise<Result<void, MemoryError>>;\r\n    async getPreference(userId: string, key: string): Promise<Result<any, MemoryError>>;\r\n\r\n    // Public memory (shared knowledge - stored in JSON file)\r\n    async storeKnowledge(key: string, value: any): Promise<Result<void, MemoryError>>;\r\n    async getKnowledge(key: string): Promise<Result<any, MemoryError>>;\r\n\r\n    // Internal: Hybrid orchestration\r\n    private async checkArchiveThreshold(userId: string, channelId: string): Promise<void>;\r\n    private async archiveToLongTerm(userId: string, channelId: string, messages: Message[]): Promise<Result<void, MemoryError>>;\r\n  }\r\n\r\n  interface MemoryEntry {\r\n    id: string;\r\n    userId: string;\r\n    channelId?: string;\r\n    type: 'short-term' | 'long-term' | 'private' | 'public';\r\n    content: string;\r\n    metadata: Record<string, any>;\r\n    timestamp: Date;\r\n    relevanceScore?: number;\r\n  }\r\n  ```\r\n- **Dependencies:**\r\n  - Node.js `fs/promises` (built-in file system operations)\r\n  - `@kadi.build/arcadedb-ability`\r\n  - Environment variables: `MEMORY_DATA_PATH`, `ARCADEDB_URL`\r\n- **Reuses:** None (new component)\r\n- **Memory Flow:**\r\n  1. New messages appended to `{memoryDataPath}/{userId}/{channelId}.json`\r\n  2. Context retrieval reads JSON file (fast, SSD-optimized)\r\n  3. When file exceeds 20 messages, summarize oldest via LLM\r\n  4. Archive summary to ArcadeDB, rewrite JSON with last 20 messages\r\n  5. Long-term searches query ArcadeDB (semantic search)\r\n- **File Structure:**\r\n  ```\r\n  ./data/memory/\r\n  ├── user-123/\r\n  │   ├── channel-456.json       # [Message[], Message[], ...] (last 20)\r\n  │   └── preferences.json        # { key: value, ... }\r\n  └── public/\r\n      └── knowledge.json          # { key: value, ... }\r\n  ```\r\n\r\n### Component 6: FileStorageAdapter\r\n\r\n- **Purpose:** Low-level file operations for short-term memory storage (JSON/MD files)\r\n- **Interfaces:**\r\n  ```typescript\r\n  class FileStorageAdapter {\r\n    constructor(dataPath: string);\r\n\r\n    // JSON file operations for conversation messages\r\n    async readJSON<T>(filePath: string): Promise<Result<T | null, FileError>>;\r\n    async writeJSON<T>(filePath: string, data: T): Promise<Result<void, FileError>>;\r\n    async appendToJSONArray<T>(filePath: string, item: T): Promise<Result<void, FileError>>;\r\n    async trimJSONArray<T>(filePath: string, keepLast: number): Promise<Result<T[], FileError>>;\r\n\r\n    // Directory operations\r\n    async ensureDirectory(dirPath: string): Promise<Result<void, FileError>>;\r\n    async listFiles(dirPath: string): Promise<Result<string[], FileError>>;\r\n    async deleteFile(filePath: string): Promise<Result<void, FileError>>;\r\n\r\n    // Markdown file operations (for long-form memory notes)\r\n    async readMarkdown(filePath: string): Promise<Result<string, FileError>>;\r\n    async writeMarkdown(filePath: string, content: string): Promise<Result<void, FileError>>;\r\n    async appendToMarkdown(filePath: string, content: string): Promise<Result<void, FileError>>;\r\n  }\r\n  ```\r\n- **Dependencies:** Node.js `fs/promises` (built-in)\r\n- **Reuses:** None (new component)\r\n- **File Locking Strategy:**\r\n  - Use atomic write pattern: write to temp file → rename (atomic on POSIX)\r\n  - For concurrent access: retry with exponential backoff on EEXIST errors\r\n  - No external locking library needed for single-agent use case\r\n\r\n### Component 7: ArcadeDBAdapter\r\n\r\n- **Purpose:** Low-level database operations for ArcadeDB persistent storage\r\n- **Interfaces:**\r\n  ```typescript\r\n  class ArcadeDBAdapter {\r\n    constructor(dbUrl: string);\r\n    async connect(): Promise<Result<void, DatabaseError>>;\r\n    async disconnect(): Promise<Result<void, DatabaseError>>;\r\n    async query(cypher: string, params?: Record<string, any>): Promise<Result<any[], DatabaseError>>;\r\n    async createVertex(type: string, properties: Record<string, any>): Promise<Result<string, DatabaseError>>;\r\n    async createEdge(from: string, to: string, type: string, properties?: Record<string, any>): Promise<Result<void, DatabaseError>>;\r\n  }\r\n  ```\r\n- **Dependencies:** `@kadi.build/arcadedb-ability`\r\n- **Reuses:** None (new component)\r\n\r\n### Component 8: DeployService\r\n\r\n- **Purpose:** Self-deployment orchestration for Model Manager Gateway to Digital Ocean\r\n- **Interfaces:**\r\n  ```typescript\r\n  class DeployService {\r\n    constructor(config: DeployConfig);\r\n    async deployModelManager(): Promise<Result<DeploymentResult, DeployError>>;\r\n    async generateAPIKey(gatewayUrl: string, adminKey: string): Promise<Result<string, DeployError>>;\r\n    async registerOpenAIModels(gatewayUrl: string, adminKey: string, openaiKey: string): Promise<Result<string[], DeployError>>;\r\n    async updateAgentConfig(gatewayUrl: string, apiKey: string): Promise<Result<void, DeployError>>;\r\n  }\r\n\r\n  interface DeployConfig {\r\n    dropletRegion: string;          // 'nyc1', 'sfo3', etc.\r\n    dropletSize: string;            // 's-2vcpu-2gb'\r\n    containerImage: string;         // 'model-manager-agent:0.0.8'\r\n    adminKey: string;               // Admin key for gateway\r\n    openaiKey?: string;             // Optional for OpenAI model registration\r\n  }\r\n\r\n  interface DeploymentResult {\r\n    gatewayUrl: string;\r\n    apiKey: string;\r\n    deploymentId: string;\r\n    registeredModels: string[];\r\n  }\r\n  ```\r\n- **Dependencies:**\r\n  - `@kadi.build/deploy-ability`\r\n  - `@kadi.build/kadi-secret` (for storing generated API key)\r\n- **Reuses:** None (new component)\r\n\r\n### Component 9: FileManagerProxy\r\n\r\n- **Purpose:** Unified interface for accessing file management abilities via KADI broker\r\n- **Interfaces:**\r\n  ```typescript\r\n  class FileManagerProxy {\r\n    constructor(client: KadiClient);\r\n\r\n    // Local-Remote File Manager\r\n    async startFileServer(directory: string, port?: number): Promise<Result<FileServerInfo, FileError>>;\r\n    async stopFileServer(serverId: string): Promise<Result<void, FileError>>;\r\n\r\n    // Cloud File Manager\r\n    async uploadToCloud(provider: string, localPath: string, remotePath: string): Promise<Result<void, FileError>>;\r\n    async downloadFromCloud(provider: string, remotePath: string, localPath: string): Promise<Result<void, FileError>>;\r\n    async listCloudFiles(provider: string, path: string): Promise<Result<CloudFile[], FileError>>;\r\n\r\n    // Container Registry\r\n    async shareContainer(containerName: string): Promise<Result<ContainerRegistryInfo, FileError>>;\r\n    async stopRegistry(registryId: string): Promise<Result<void, FileError>>;\r\n\r\n    // SSH/SCP File Management\r\n    async uploadViaSSH(host: string, localPath: string, remotePath: string): Promise<Result<void, FileError>>;\r\n    async downloadViaSSH(host: string, remotePath: string, localPath: string): Promise<Result<void, FileError>>;\r\n    async executeRemoteCommand(host: string, command: string): Promise<Result<string, FileError>>;\r\n  }\r\n\r\n  interface FileServerInfo {\r\n    serverId: string;\r\n    localUrl: string;\r\n    tunnelUrl: string;\r\n  }\r\n\r\n  interface ContainerRegistryInfo {\r\n    registryId: string;\r\n    registryUrl: string;\r\n    loginCommand: string;\r\n    pullCommand: string;\r\n  }\r\n  ```\r\n- **Dependencies:**\r\n  - `KadiClient` for broker access\r\n  - File abilities accessed via `protocol.invokeTool()`, not direct imports\r\n- **Reuses:** Existing tool invocation pattern from `index.ts` lines 310-318\r\n\r\n## Data Models\r\n\r\n### Memory Data Models\r\n\r\n```typescript\r\n// Short-term memory (conversation context)\r\ninterface ConversationMessage {\r\n  id: string;\r\n  userId: string;\r\n  channelId: string;\r\n  role: 'user' | 'assistant';\r\n  content: string;\r\n  timestamp: Date;\r\n  metadata: {\r\n    platform: 'slack' | 'discord';\r\n    threadId?: string;\r\n  };\r\n}\r\n\r\n// Long-term memory (summarized conversations)\r\ninterface ConversationSummary {\r\n  id: string;\r\n  userId: string;\r\n  channelId: string;\r\n  summary: string;\r\n  messageCount: number;\r\n  startDate: Date;\r\n  endDate: Date;\r\n  topics: string[];\r\n  relevanceScore: number;\r\n}\r\n\r\n// Private memory (user preferences)\r\ninterface UserPreference {\r\n  userId: string;\r\n  key: string;\r\n  value: any;\r\n  updatedAt: Date;\r\n}\r\n\r\n// Public memory (shared knowledge)\r\ninterface PublicKnowledge {\r\n  key: string;\r\n  value: any;\r\n  source: string;\r\n  confidence: number;\r\n  createdAt: Date;\r\n  accessCount: number;\r\n}\r\n```\r\n\r\n### Provider Data Models\r\n\r\n```typescript\r\ninterface ProviderStatus {\r\n  name: string;\r\n  isHealthy: boolean;\r\n  lastHealthCheck: Date;\r\n  consecutiveFailures: number;\r\n  averageResponseTime: number;\r\n}\r\n\r\ninterface ProviderError {\r\n  code: string;               // 'AUTH_FAILED', 'RATE_LIMIT', 'TIMEOUT', etc.\r\n  message: string;\r\n  provider: string;\r\n  timestamp: Date;\r\n  retryable: boolean;\r\n}\r\n```\r\n\r\n### Deployment Data Models\r\n\r\n```typescript\r\ninterface DeploymentConfig {\r\n  platform: 'digital-ocean' | 'akash';\r\n  region: string;\r\n  resources: {\r\n    cpu: number;\r\n    memory: string;\r\n    storage: string;\r\n  };\r\n  containerImage: string;\r\n  environment: Record<string, string>;\r\n}\r\n\r\ninterface DeploymentStatus {\r\n  deploymentId: string;\r\n  status: 'pending' | 'deploying' | 'running' | 'failed' | 'stopped';\r\n  gatewayUrl?: string;\r\n  apiKey?: string;\r\n  createdAt: Date;\r\n  lastUpdated: Date;\r\n}\r\n```\r\n\r\n## Error Handling\r\n\r\n### Error Scenarios\r\n\r\n1. **Provider Unavailable (Network/API Failure)**\r\n   - **Handling:** ProviderManager marks provider unhealthy, attempts fallback provider\r\n   - **User Impact:** \"Switching to backup AI provider...\" message shown if fallback succeeds\r\n   - **Code:** Return `{ success: false, error: { code: 'PROVIDER_UNAVAILABLE', retryable: true } }`\r\n\r\n2. **Authentication Failure (Invalid API Key)**\r\n   - **Handling:** ProviderManager marks provider unhealthy, logs error with obfuscated key\r\n   - **User Impact:** \"AI provider authentication failed. Please check configuration.\" message\r\n   - **Code:** Return `{ success: false, error: { code: 'AUTH_FAILED', retryable: false } }`\r\n\r\n3. **Rate Limit Exceeded**\r\n   - **Handling:** ProviderManager implements exponential backoff (5s, 10s, 20s), marks provider temporarily unavailable\r\n   - **User Impact:** \"AI provider is rate limited. Retrying in X seconds...\" message\r\n   - **Code:** Return `{ success: false, error: { code: 'RATE_LIMIT', retryable: true } }`\r\n\r\n4. **Memory File Read/Write Failure**\r\n   - **Handling:** FileStorageAdapter retries with exponential backoff, falls back to in-memory for session, logs error\r\n   - **User Impact:** Warning logged, conversations proceed without persistent memory (session-only context)\r\n   - **Code:** Agent degrades gracefully, no user-facing error for non-critical memory failures\r\n\r\n5. **File Operation Failure (Permission Denied, Not Found)**\r\n   - **Handling:** FileManagerProxy returns detailed error with path and permission info\r\n   - **User Impact:** \"File operation failed: [specific error]. Check permissions and path.\"\r\n   - **Code:** Return `{ success: false, error: { code: 'FILE_ERROR', message: details } }`\r\n\r\n6. **Deployment Failure (Insufficient Resources, Invalid Config)**\r\n   - **Handling:** DeployService validates configuration before deployment, rolls back on failure\r\n   - **User Impact:** \"Deployment failed: [specific reason]. Rolled back successfully.\"\r\n   - **Code:** Return `{ success: false, error: { code: 'DEPLOY_FAILED', message: details } }`\r\n\r\n7. **All Providers Failed**\r\n   - **Handling:** ProviderManager returns aggregated error listing all provider failures\r\n   - **User Impact:** \"All AI providers unavailable. Please try again later. [Details: ...]\"\r\n   - **Code:** Return `{ success: false, error: { code: 'ALL_PROVIDERS_FAILED', providers: [...] } }`\r\n\r\n## Testing Strategy\r\n\r\n### Unit Testing\r\n\r\n- **Provider Tests**: Mock HTTP responses for Model Manager, test Anthropic provider with test keys\r\n- **Memory Tests**: Use temp directory for file storage unit tests, verify JSON read/write/append operations\r\n- **Provider Manager Tests**: Mock provider responses, test fallback logic with controlled failures\r\n- **File Proxy Tests**: Mock KADI protocol invocations, verify request formatting\r\n\r\n### Integration Testing\r\n\r\n- **End-to-End Provider Flow**: Real API calls to Model Manager test deployment and Anthropic with test keys\r\n- **Memory Persistence**: Verify JSON files persist across service restarts, test ArcadeDB archival\r\n- **Deployment Flow**: Use Digital Ocean test droplet, verify full deployment cycle\r\n- **File Operations**: Use test directories and containers, verify tunnel creation and file transfers\r\n\r\n### End-to-End Testing\r\n\r\n- **Slack Bot with Multi-Provider**: Send test messages, verify provider switching and fallback\r\n- **Discord Bot with Memory**: Have conversation, restart bot, verify context restored\r\n- **Deployment Test**: Deploy Model Manager, generate API key, update agent config, make LLM request\r\n- **File Sharing Test**: Start file server, verify public URL accessible, upload to cloud storage\r\n",
  "fileStats": {
    "size": 27066,
    "lines": 667,
    "lastModified": "2025-12-07T19:31:11.676Z"
  },
  "comments": []
}